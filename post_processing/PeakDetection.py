#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Mar 15 12:22:07 2018

@author: jmotyka
"""

import peakutils
from peakutils.plot import plot as pplot

import matplotlib.pyplot as plt

# Creating multiple instances in an array
# https://stackoverflow.com/questions/1807026/initialize-a-list-of-objects-in-python
# 
# lst = [SignalPeaks() for _ in range(5)]
# lst[0].set_name('john')
# lst[1].set_name('paul')
# lst[2].set_name('ringo')
# lst[3].set_name('george')
#
# tmp = lst[0].get_name()
# print( tmp )
#
# Destroying ringo
# del lst[2]

import sys  
sys.path.append('/Users/jmotyka/Python/Library/')
from FIR_Filter_Utils import *


# PeakDetection.py
#
# Class containing routine to detect peaks in time-series and align in time (by
#   finding the relative time-shifts between signals)
#
class SignalPeaks:
    #PeakDetection:
    """
        Class to detect peaks in a time-series and store the results in a peak-
          list (consisting of inds, N, t, A, w, tNext).
    """

    # A class variable, counting the number of signals
    __numOfSigs = 0

    # Constructor
    def __init__(self, name=''):
        self.__name = name
        SignalPeaks.__numOfSigs = SignalPeaks.__numOfSigs + 1
        print( 'Constructor: ' + self.__name + ' object created (instance #' + str(SignalPeaks.__numOfSigs) + ')' )
        
        # The following are individual (different for different signals)
        #self.name = ''
        
        #
        self.__signal = { 'validSignal':False,
                          'time':{},
                          'signal':{},
                          'fSamp':{},
                          'dt':{},            # Derived from fSamp: dt = 1.0/fSamp
                          'numOfPts':0,       # Derived from signal: N = len(t)
                          'filtSig':{},       # Generated by smoothing signal
                          'maxFiltVal':{} }   # Calculated from smoothed signal

        # Computed from input signal
        self.__peakList = { 'peakInds':{},
                            'numOfPeaks':{},
                            'peakTimes':{},
                            'peakAmps':{},
                            'peakWidths':{},
                            'timeToNextPeak':{} }

        #
        # These can be the same between signals
        self.__smoothingParams = { 'pts':{},
                                   'method':'triang' }

        self.__searchThresh = { 'tSep':{},
                                'minAmp':{},
                                'widthAmp':{} }


    # Destructor
    def __del__(self):
        class_name = self.__class__.__name__
        print( 'Destructor: ' + self.__name, 'object destroyed' )


    # Setter: import the signal data to the class
    def set_name(self, name):
        self.__name = name


    # Setter: import the signal data to the class
    def get_name(self):
        return( self.__name )


    # Setter: import the signal data to the class
    def set_signal(self, time, signal, fSamp):
        self.__signal['validSignal'] = True

        self.__signal['time']   = time
        self.__signal['signal'] = signal
        self.__signal['fSamp']  = fSamp
        
        #
        self.__signal['dt'] = 1.0 / fSamp
        self.__signal['numOfPts'] = len(time)


    # Setter: set the smoothing filter parameters used by the class
    def set_smoothingParameters(self, pts=30, smoothingMethod='triang'):
        self.__smoothingParams['pts']    = pts
        self.__smoothingParams['method'] = smoothingMethod
        #print( 'Smoothing parameters: ' + str(self.__smoothingParams['pts']) + \
        #                                  ' / ' + str(self.__smoothingParams['method']) )

    #
    def set_peakSeparationTime(self, tSep):
        self.__searchThresh['tSep'] = tSep


    #
    def set_widthThreshold(self, widthThresh):
        self.__searchThresh['widthAmp'] = widthThresh


    #
    def set_amplitudeThreshold(self, ampThresh):
        self.__searchThresh['minAmp'] = ampThresh


    #
    def SmoothData(self):
        #
        self.__signal['filtSig'] = SymmetricFIR(self.__smoothingParams['pts']+1, \
                                                self.__smoothingParams['method'], \
                                                self.__signal['signal'])

        # Maximum Value
        self.__signal['maxFiltVal'] = np.max(self.__signal['filtSig'])


    #
    def FindPeaks(self):
        # The amplitude threshold is percentage of maximum amplitude in the
        #   signal
        thresh = self.__searchThresh['minAmp'] / self.__signal['maxFiltVal']

        # Use peakutils to find the peaks in the time-series
        self.__peakList['peakInds'] = peakutils.indexes(self.__signal['filtSig'], \
                                                        thresh, \
                                                        min_dist=self.__searchThresh['tSep']*self.__signal['fSamp'])

        # Number of peaks
        self.__peakList['numOfPeaks'] = len(self.__peakList['peakInds'])

        # Peak times and values
        self.__peakList['peakTimes'] = np.zeros(self.__peakList['numOfPeaks'])
        self.__peakList['peakAmps']  = np.zeros(self.__peakList['numOfPeaks'])

        pl_ind = 0
        for ind in self.__peakList['peakInds']:
            self.__peakList['peakTimes'][pl_ind] = self.__signal['time'][ind]
            self.__peakList['peakAmps'][pl_ind]  = self.__signal['filtSig'][ind]
            pl_ind = pl_ind + 1

        #
        self.__peakList['peakWidths'] = self.MeasureWidths()

        #
        self.__peakList['timeToNextPeak'] = self.FindSeparationTimes()

        #print( self.__peakList )

    #
    def MeasureWidths(self):
        #
        w = np.zeros(self.__peakList['numOfPeaks'])

        pl_ind = 0
        for ind in self.__peakList['peakInds']:
            # Step back
            k = 1
            tmin = 0
            while k < self.__searchThresh['tSep'] * self.__signal['fSamp']:
                val = self.__signal['filtSig'][ind - k]
                if val < self.__searchThresh['widthAmp']:
                    tmin = -k / self.__signal['fSamp']
                    #print([ind - k, val, tmin])
                    break
                k = k + 1

            # Step forward
            k = 1
            tmax = 0
            # what if the check on k is exceeded and the width isn't determined?
            while k < self.__searchThresh['tSep'] * self.__signal['fSamp']:
                val = self.__signal['filtSig'][ind + k]
                if val < self.__searchThresh['widthAmp']:
                    tmax = k / self.__signal['fSamp']
                    #print([ind - k, val, tmax])
                    break
                k = k + 1

            # Compute width
            w[pl_ind] = tmax - tmin
            pl_ind = pl_ind + 1
            
        return w


    def FindSeparationTimes(self):
        #
        pl_ind = 0
        sepTime = np.zeros(self.__peakList['numOfPeaks'])
        for ind in self.__peakList['peakInds']:
            #
            if ind < self.__peakList['peakInds'][-1]:
                sepTime[pl_ind] = self.__signal['time'][self.__peakList['peakInds'][pl_ind+1]] - \
                                  self.__signal['time'][self.__peakList['peakInds'][pl_ind+0]]
            else:
                sepTime[pl_ind] = 0.0
            pl_ind = pl_ind + 1

        return sepTime




    @classmethod
    def AlignPeaks(cls):
        """
            Prints the current population
        """
        #print("We have {:d} robots.".format(cls.population))
        print( 1 )
        
        
    @classmethod
    def HowManySignals(cls):
        print("SignalPeaks has", SignalPeaks.__numOfSigs, " objects.")



    #@classmethod
    #def xxx(self, MyClass myclass, number, foobar)
    # References:
    #   1) https://stackoverflow.com/questions/2489669/function-parameter-types-in-python
    #   2) http://openbookproject.net/thinkcs/python/english3e/classes_and_objects_I.html
    #      (Section 15.8)
    def CalculateSimilarityMatrix(self, other):
        #
        #print(self.__peakList['peakInds'])
        #print(other.__peakList['peakTimes'])

        #
        similarityMatrix_Amp   = np.zeros([self.__peakList['numOfPeaks'], other.__peakList['numOfPeaks']])
        similarityMatrix_Width = np.zeros([self.__peakList['numOfPeaks'], other.__peakList['numOfPeaks']])
        similarityMatrix       = np.zeros([self.__peakList['numOfPeaks'], other.__peakList['numOfPeaks']])

        mult = 1.0

        #
        for rowNum in range(self.__peakList['numOfPeaks']):
            for colNum in range(other.__peakList['numOfPeaks']):
                similarityMatrix_Amp[rowNum,colNum] = abs(self.__peakList['peakAmps'][rowNum] - \
                                                          other.__peakList['peakAmps'][colNum])
                similarityMatrix_Amp[rowNum,colNum] = similarityMatrix_Amp[rowNum,colNum] / ( mult * np.max(np.array([self.__peakList['peakAmps'][rowNum], other.__peakList['peakAmps'][colNum]])) )
                similarityMatrix_Amp[rowNum,colNum] = 1.0 - similarityMatrix_Amp[rowNum,colNum]
                
                similarityMatrix_Width[rowNum,colNum] = abs(self.__peakList['peakWidths'][rowNum] - \
                                                            other.__peakList['peakWidths'][colNum])
                similarityMatrix_Width[rowNum,colNum] = similarityMatrix_Width[rowNum,colNum] / ( mult * np.max(np.array([self.__peakList['peakWidths'][rowNum], other.__peakList['peakWidths'][colNum]])) )
                similarityMatrix_Width[rowNum,colNum] = 1.0 - similarityMatrix_Width[rowNum,colNum]
                
                # Treating the amplitude and with similarity matrices as
                #   probability matrices, multplying the two will generate
                #   the probability of amp and width similarity.
                similarityMatrix[rowNum,colNum] = similarityMatrix_Amp[rowNum,colNum] * \
                                                  similarityMatrix_Width[rowNum,colNum]
        
        #print(np.divide(np.floor( np.dot(similarityMatrix, 10000.0) + 0.5 ), 100.0))

        #
        similarityMatrix_row = np.zeros([self.__peakList['numOfPeaks'],other.__peakList['numOfPeaks']])
        similarityMatrix_col = np.zeros([self.__peakList['numOfPeaks'],other.__peakList['numOfPeaks']])

        for rowNum in range(self.__peakList['numOfPeaks']):
            maxVal = np.max(similarityMatrix[rowNum,:])
            similarityMatrix_row[rowNum,:] = similarityMatrix[rowNum,:] / maxVal
        #print('Sim. Matrix (row):')
        #print(np.divide(np.floor( np.dot(similarityMatrix_row, 10000.0) + 0.5 ), 100.0))

        for colNum in range(other.__peakList['numOfPeaks']):
            maxVal = np.max(similarityMatrix[:,colNum])
            similarityMatrix_col[:,colNum] = similarityMatrix[:,colNum] / maxVal
        #print('Sim. Matrix (col):')
        #print(np.divide(np.floor( np.dot(similarityMatrix_col, 10000.0) + 0.5 ), 100.0))

        similarityMatrix = 0.5 * (similarityMatrix_row + similarityMatrix_col)
        #print('Sim. Matrix (%):')
        #print( np.divide(np.floor(np.dot(similarityMatrix, 10000.0) + 0.5), 100.0) )

        return similarityMatrix


    def FindOptimalAlignment(self, other):
        #
        similarityMatrix = self.CalculateSimilarityMatrix(other)
        #print( '---> FindOptimalAlignment' )
        #print( 'Sim Matrix:' )
        #print( np.divide(np.floor(np.dot(similarityMatrix, 1000.0) + 0.5), 10.0) )

        # Calculate the manimum potential number of overlapping peaks
        maxOverlap = np.min([self.__peakList['numOfPeaks'], \
                             other.__peakList['numOfPeaks']])

        # Either there are more peaks in the first signal or both signals have
        #   the same number of peaks
        if self.__peakList['numOfPeaks'] >= other.__peakList['numOfPeaks']:
            #
            nB = other.__peakList['numOfPeaks']
            nA = self.__peakList['numOfPeaks']
            indB_Start = -other.__peakList['numOfPeaks']
            nA_Past    = -1

            nC = self.__peakList['numOfPeaks'] + \
                 other.__peakList['numOfPeaks'] - 1

            # Initialize the matrix that holds the time-shift estimate (col 1)
            #   and the probability estimate (col 2)
            SimilarityResults = np.zeros([nC,2])

            #
            for caseNum in range(nC):
                indA = np.arange(self.__peakList['numOfPeaks']-1-caseNum, \
                                 self.__peakList['numOfPeaks']-1-caseNum+maxOverlap,1)
                ind  = np.where( indA > self.__peakList['numOfPeaks']-1 )
                indA = np.delete( indA, ind )
                ind  = np.where( indA < 0 )
                indA = np.delete( indA, ind )

                nA = len(indA)
                if nA != nA_Past:
                    indB_Start = indB_Start + 1
                nA_Past = nA

                indB = np.arange(indB_Start,indB_Start+maxOverlap,1)
                ind  = np.where( indB > other.__peakList['numOfPeaks']-1 )
                indB = np.delete( indB, ind )
                ind  = np.where( indB < 0 )
                indB = np.delete( indB, ind )

                simVal = 0.0
                for i in range(nA):
                    simVal = simVal + similarityMatrix[indA[i],indB[i]]
                simVal = simVal / nA

                dT = self.__peakList['peakTimes'][indA]  - \
                     other.__peakList['peakTimes'][indB]

                SimilarityResults[caseNum,0] = simVal
                SimilarityResults[caseNum,1] = np.mean( dT )
        else:
            nB = other.__peakList['numOfPeaks']
            nA = self.__peakList['numOfPeaks']
        
            indA_Start = -self.__peakList['numOfPeaks']
            nB_Past    = -1
        
            nC = self.__peakList['numOfPeaks'] + \
                 other.__peakList['numOfPeaks'] - 1

            SimilarityResults = np.zeros([nC,2])
            for caseNum in range(nC):
                indB = np.arange(other.__peakList['numOfPeaks']-1-caseNum, \
                                 other.__peakList['numOfPeaks']-1-caseNum+maxOverlap,1)
                ind  = np.where( indB > other.__peakList['numOfPeaks']-1 )
                indB = np.delete( indB, ind )
                ind  = np.where( indB < 0 )
                indB = np.delete( indB, ind )

                nB = len(indB)
                if nB != nB_Past:
                    indA_Start = indA_Start + 1
                nB_Past = nB

                indA = np.arange(indA_Start,indA_Start+maxOverlap,1)
                ind  = np.where( indA > self.__peakList['numOfPeaks']-1 )
                indA = np.delete( indA, ind )
                ind  = np.where( indA < 0 )
                indA = np.delete( indA, ind )
                # Indices seem correct
                #print([indA, indB])

                simVal = 0.0
                for i in range(nB):
                    simVal = simVal + similarityMatrix[indA[i],indB[i]]
                simVal = simVal / nB
                # simVals seem correct
                #print(simVal)
            
                dT = self.__peakList['peakTimes'][indA]  - \
                     other.__peakList['peakTimes'][indB]
                #
                #print(dT)

                SimilarityResults[caseNum,0] = simVal
                SimilarityResults[caseNum,1] = np.mean( dT )

        ind = np.argsort(SimilarityResults[:,0])
        SimilarityResults[:,0] = SimilarityResults[ind,0]
        SimilarityResults[:,1] = SimilarityResults[ind,1]

        return np.array([[SimilarityResults[-1,1], SimilarityResults[-1,0]], \
                         [SimilarityResults[-2,1], SimilarityResults[-2,0]], \
                         [SimilarityResults[-3,1], SimilarityResults[-3,0]], \
                         [SimilarityResults[-4,1], SimilarityResults[-4,0]], \
                         [SimilarityResults[-5,1], SimilarityResults[-5,0]]])
        #print(SimilarityResults)

    def FindTimeOffset(self, other):
        # Peak detection compares two similar signals (A and B) and tries to
        #   determine the similarity between them in order to establish the
        #   time-shift between the signal.
        # Process:
        #   1) For each signal provide time, signal, sampling-rate, number of
        #      pts)
        #   2) Minimum separation time between peaks
        #   3) Smoothing parameters (number of points, method to use)
        #   4) Value at which to compute width
        #
        peakDetectData = PD_Initialize(data)

        # A) Smooth the data
        peakDetectData = PD_SmoothData(peakDetectData)

        # B) Find the peaks in the signals
        peakDetectData = PD_FindPeaks(peakDetectData)

        # C) Find the peak-amplitudes, widths, and separation-times in the
        #    signals
        peakDetectData = PD_FindPeakAmps(peakDetectData)
        peakDetectData = PD_FindPeakWidths(peakDetectData)
        peakDetectData = PD_FindSeparationTimes(peakDetectData)

        # D) Populate the peak-lists
        peakDetectData = PD_FormPeakLists(peakDetectData)
    
        # E) Use the information in the peak-lists to find the similarity-
        #    matrix
        peakDetectData = PD_CalculateSimilarityMatrix(peakDetectData)

        #print( peakDetectData )
    
        # F) Return the top three dT values
        dT = PD_FindOptimalAlignment(peakDetectData)

        return dT[0,0]


    def PlotAdjustedSignal(self, other, dT, figNum):
        #
        plt.figure(figNum)
        plt.clf()
        plt.plot(self.__signal['time'], self.__signal['signal'])
        plt.grid(True)
        plt.plot(other.__signal['time']+dT, other.__signal['signal'])
        titleStr = self.__name + ' and ' + other.__name + ' Signals (time-adjusted) versus Time'
        plt.title(titleStr)
        plt.xlabel('Time')
        plt.ylabel('Signal')

        return( figNum + 1 )
